{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c31b2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "936bead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_feats(data, dense_feats, sparse_feats):\n",
    "    \"\"\"\n",
    "    (1)对于数值型特征，用0填充，然后进行log变换\n",
    "    (2)对于类别型特征，用-1填充，然后进行类别编码\n",
    "    \"\"\"\n",
    "    d = data.copy()\n",
    "    d[dense_feats]  = d[dense_feats].fillna(0.0)\n",
    "    d[sparse_feats] = d[sparse_feats].fillna(\"-1\")\n",
    "    for col in d.columns:\n",
    "        if col in dense_feats:\n",
    "            d[col] = d[col].apply(lambda x: np.log(x+1) if x>-1 else -1)\n",
    "        elif col in sparse_feats:\n",
    "            d[col] = LabelEncoder().fit_transform(d[col])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c97299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(data, dense_feats, sparse_feats):\n",
    "    # ------------- linear -----------------\n",
    "    # 对于数值型特征，构造其模型输入与加权求和的代码\n",
    "    # 注释中 ? 表示输入数据的 batch_size\n",
    "    dense_inputs = []\n",
    "    for f in dense_feats:\n",
    "        _input = Input([1], name=f)\n",
    "        dense_inputs.append(_input)\n",
    "    # 将输入拼接到一起，方便连接到 Dense 层\n",
    "    concat_dense_inputs = Concatenate(axis=1)(dense_inputs)     # ?, 13\n",
    "    # 然后连上输出为1个单元的全连接层，表示对 dense 变量的加权求和\n",
    "    fst_order_dense_layer = Dense(1)(concat_dense_inputs)       # ?, 1\n",
    "\n",
    "    # 对于离散型特征，需要进行 embedding 变换\n",
    "    # 例如原一个离散特征，可能枚举值有n个，则embedding为n*1\n",
    "    embedding_size = 1\n",
    "    sparse_inputs = []\n",
    "    for f in sparse_feats:\n",
    "        _input = Input([1], name=f)\n",
    "        sparse_inputs.append(_input)\n",
    "    sparse_1d_embed = []\n",
    "    for i, _input in enumerate(sparse_inputs):\n",
    "        f = sparse_feats[i]\n",
    "        voc_size = data[f].nunique()\n",
    "        # 使用 l2 正则化防止过拟合\n",
    "        reg = tf.keras.regularizers.l2(0.5)\n",
    "        _embed = Embedding(voc_size, embedding_size, embeddings_regularizer=reg)(_input)\n",
    "        # 由于 Embedding 的结果是二维的，\n",
    "        # 因此需要在 Embedding 之后加入 Dense 层，则需要先连接上 Flatten 层\n",
    "        _embed = Flatten()(_embed)\n",
    "        sparse_1d_embed.append(_embed)\n",
    "    # 对每个 embedding lookup 的结果 wi 求和\n",
    "    fst_order_sparse_layer = Add()(sparse_1d_embed)\n",
    "\n",
    "    # 将数值型特征与离散型特征的结果求和\n",
    "    liner_part = Add()([fst_order_dense_layer, fst_order_sparse_layer])\n",
    "\n",
    "    # ------------- fm -----------------\n",
    "    # 仅对离散特征进行交叉\n",
    "    # embedding_size \n",
    "    embedding_size = 8\n",
    "    # 只考虑 sparse 的二阶交叉\n",
    "    sparse_kd_embed = []\n",
    "    for i, _input in enumerate(sparse_inputs):\n",
    "        f = sparse_feats[i]\n",
    "        voc_size = data[f].nunique()\n",
    "        reg = tf.keras.regularizers.l2(0.7)\n",
    "        _embed = Embedding(voc_size, embedding_size, embeddings_regularizer=reg)(_input)\n",
    "        sparse_kd_embed.append(_embed)\n",
    "    # 通过拆隐向量求和公式可得到 和的平方 - 平方的和\n",
    "    # (1) 将所有 sparse 特征 (?, 1, k) 的embedding拼接起来\n",
    "    #     得到 (?, n, k) 的矩阵，其中 n 为特征数，k为embedding_size\n",
    "    concat_sparse_kd_embed = Concatenate(axis=1)(sparse_kd_embed)   # ?, n, k\n",
    "    # (2) 先求和再平方\n",
    "    sum_kd_embed = Lambda(lambda x: K.sum(x, axis=1))(concat_sparse_kd_embed)   # ?, k\n",
    "    square_sum_kd_embed = Multiply()([sum_kd_embed, sum_kd_embed])\n",
    "    # (3) 先平方再求和\n",
    "    square_kd_embed = Multiply()([concat_sparse_kd_embed,concat_sparse_kd_embed])   # ?, n, k\n",
    "    sum_square_kd_embed = Lambda(lambda x: K.sum(x, axis=1))(square_kd_embed)   # ?, k\n",
    "    # (4) 相减除以2\n",
    "    sub = Subtract()([square_sum_kd_embed, sum_square_kd_embed])    # ?, k\n",
    "    sub = Lambda(lambda x: x*0.5)(sub)  # ?, k\n",
    "    snd_order_sparse_layer = Lambda(lambda x: K.sum(x, axis=1, keepdims=True))(sub) # ?, 1\n",
    "\n",
    "    # ------------- dnn -----------------\n",
    "    # 注意 dnn 部分是对 fm 中已embedding的隐向量学习\n",
    "    flatten_sparse_embed = Flatten()(concat_sparse_kd_embed)    # ?, n*k\n",
    "    fc_layer = Dropout(0.5)(Dense(128, activation=\"relu\")(flatten_sparse_embed))    # ?, 128\n",
    "    fc_layer = Dropout(0.5)(Dense(128, activation=\"relu\")(fc_layer))    # ?, 128\n",
    "    fc_layer = Dropout(0.5)(Dense(128, activation=\"relu\")(fc_layer))    # ?, 128\n",
    "    fc_layer_output = Dense(1)(fc_layer)    # ?, 1\n",
    "\n",
    "    # ------------- deepfm -----------------\n",
    "    output_layer = Add()([liner_part, snd_order_sparse_layer, fc_layer_output])\n",
    "    output_layer = Activation(\"sigmoid\")(output_layer)\n",
    "\n",
    "    # 模型编译\n",
    "    model = Model(dense_inputs+sparse_inputs, output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95208f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train_1m.txt\", sep=\"\\t\")\n",
    "cols  = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a913a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_feats  = [f for f in cols if f[0] == \"I\"]\n",
    "sparse_feats = [f for f in cols if f[0] == \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16b262a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = process_feats(train, dense_feats, sparse_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ebabe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.iloc[:800000]\n",
    "valid_data = data.iloc[800000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b288cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dense_x  = [train_data[f].values for f in dense_feats]\n",
    "train_sparse_x = [train_data[f].values for f in sparse_feats]\n",
    "train_label    = [train_data[\"Label\"].values]\n",
    "\n",
    "val_dense_x  = [valid_data[f].values for f in dense_feats]\n",
    "val_sparse_x = [valid_data[f].values for f in sparse_feats]\n",
    "val_label    = [valid_data[\"Label\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec9db238",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model(data, dense_feats, sparse_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08458bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\"binary_crossentropy\", tf.keras.metrics.AUC(name=\"auc\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95d428f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xiaoju/jupyterlab/venv/lib64/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 800000 samples, validate on 200000 samples\n",
      "Epoch 1/5\n",
      "800000/800000 [==============================] - 657s 821us/sample - loss: 30.0088 - binary_crossentropy: 0.5291 - auc: 0.6975 - val_loss: 0.5878 - val_binary_crossentropy: 0.4951 - val_auc: 0.7364\n",
      "Epoch 2/5\n",
      "800000/800000 [==============================] - 633s 791us/sample - loss: 0.5996 - binary_crossentropy: 0.4992 - auc: 0.7357 - val_loss: 0.6157 - val_binary_crossentropy: 0.4927 - val_auc: 0.7397\n",
      "Epoch 3/5\n",
      "800000/800000 [==============================] - 631s 789us/sample - loss: 0.6149 - binary_crossentropy: 0.4978 - auc: 0.7377 - val_loss: 0.6060 - val_binary_crossentropy: 0.4934 - val_auc: 0.7399\n",
      "Epoch 4/5\n",
      "800000/800000 [==============================] - 622s 777us/sample - loss: 0.6237 - binary_crossentropy: 0.4971 - auc: 0.7387 - val_loss: 0.6314 - val_binary_crossentropy: 0.4930 - val_auc: 0.7406\n",
      "Epoch 5/5\n",
      "800000/800000 [==============================] - 613s 766us/sample - loss: 0.6252 - binary_crossentropy: 0.4969 - auc: 0.7391 - val_loss: 0.6257 - val_binary_crossentropy: 0.4924 - val_auc: 0.7404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faf0e5cacf8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dense_x+train_sparse_x, train_label,\n",
    "          epochs=5, batch_size=256,\n",
    "          validation_data=(val_dense_x+val_sparse_x, val_label)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05f994c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_pred = model.predict(val_dense_x+val_sparse_x, batch_size=256)\n",
    "val_label_pred_class = list(map(lambda i: 1 if i > 0.32 else 0, val_label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c3edaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.254585"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(val_label_pred_class) / len(val_label_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de8a819e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.251165"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(val_label[0]) / len(val_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1eb1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
